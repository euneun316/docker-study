version: "3.6"

services:

# spark
  jupyterlab:
    image: imok2/jupyterlab:spark3.1.2
    container_name: jupyterlab
    restart: always
    ports:
      - 8886:8886
    volumes:
     - shared-workspace:/opt/workspace
    networks:
      - localnet
  
  spark-master:
    image: imok2/spark-master:spark3.1.2
    container_name: spark-master
    restart: always
    ports:
      - 8080:8080
      - 7077:7077
    volumes:
      - shared-workspace:/opt/workspace
    networks:
      - localnet

  spark-worker-1:
    image: imok2/spark-worker:spark3.1.2
    container_name: spark-worker-1
    restart: always
    environment:
      SPARK_WORKER_CORES: "1"
      SPARK_WORKER_MEMORY: "2048m"
    ports:
      - 8081:8081
    volumes:
      - shared-workspace:/opt/workspace
    networks:
      - localnet
    depends_on:
      - spark-master

  spark-worker-2:
    image: imok2/spark-worker:spark3.1.2
    container_name: spark-worker-2
    restart: always
    environment:
      SPARK_WORKER_CORES: "1"
      SPARK_WORKER_MEMORY: "2048m"
    ports:
      - 8082:8081
    volumes:
      - shared-workspace:/opt/workspace
    networks:
      - localnet
    depends_on:
      - spark-master

# db
  db1:
    image: mongo:5.0.5
    container_name: mongodb2
    restart: always
    environment:
      MONGO_INITDB_ROOT_USERNAME: root
      MONGO_INITDB_ROOT_PASSWORD: 1234
    ports:
      - "27017:27017"
    volumes:
        - mongodb2:/data/db
        - mongodb_config2:/data/configdb
    networks:
      - localnet
  
  db2:          
    # image: mysql:5.7.19
    image: mysql:5.7 # M1
    platform: linux/x86_64 # M1
    container_name: mysql2 
    restart: always
    environment:
      MYSQL_ROOT_PASSWORD: 1234
    command:
      # - --default-authentication-plugin=mysql_native_password
      - --character-set-server=utf8mb4
      - --collation-server=utf8mb4_unicode_ci
    ports:
      - "3306:3306"
    volumes:
      - mysql_data2:/var/lib/mysql
    networks:
      - localnet

# hdfs
  namenode:
    image: imok2/hadoop-namenode-sqoop:hadoop3.2.2-sqoop1.4.7
    container_name: namenode
    restart: always
    ports:
      - 9870:9870
      - 9000:9000
    volumes:
      - hadoop_namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=test
    env_file:
      - ./hadoop.env
    networks:
      - localnet

  datanode:
    image: imok2/hadoop-datanode:hadoop3.2.2-java8
    container_name: datanode
    restart: always
    volumes:
      - hadoop_datanode:/hadoop/dfs/data
    environment:
      SERVICE_PRECONDITION: "namenode:9870"
    env_file:
      - ./hadoop.env
    networks:
      - localnet
    depends_on:
      - namenode

  resourcemanager:
    image: imok2/hadoop-resourcemanager:hadoop3.2.2-java8
    container_name: resourcemanager
    restart: always
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864"
    env_file:
      - ./hadoop.env
    networks:
      - localnet
    depends_on:
      - namenode
      - datanode

  nodemanager1:
    image: imok2/hadoop-nodemanager:hadoop3.2.2-java8
    container_name: nodemanager
    restart: always
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864 resourcemanager:8088"
    env_file:
      - ./hadoop.env
    networks:
      - localnet
    depends_on:
      - namenode
      - datanode
      - resourcemanager

  historyserver:
    image: imok2/hadoop-historyserver:hadoop3.2.2-java8
    container_name: historyserver
    restart: always
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864 resourcemanager:8088"
    volumes:
      - hadoop_historyserver:/hadoop/yarn/timeline
    env_file:
      - ./hadoop.env
    networks:
      - localnet
    depends_on:
      - namenode
      - datanode
      - resourcemanager

# volumes
volumes:
  shared-workspace:
    name: "hadoop-distributed-file-system"
    driver: local
  mongodb2:
  mongodb_config2:
  mysql_data2:
  hadoop_namenode:
  hadoop_datanode:
  hadoop_historyserver:

# networks
networks:
  localnet:
    # attachable: true
